---
title: "AE 14: Logistic regression"
subtitle: "Model comparsion"
date: "Nov 14, 2022"
editor: visual
format: pdf
execute: 
  warning: false
  message: false
---

::: callout-important
The AE is due on GitHub by Thursday, November 17, 11:59pm.
:::

::: callout-note
As you work on the AE, post questions on Ed Discussion. We will also use this space to get responses from groups:

-   10:15am lecture: <https://edstem.org/us/courses/26900/discussion/2154489>

-   3:30pm lecture : <https://edstem.org/us/courses/26900/discussion/2154491>
:::

As you work on the AE, post questions on Ed Discussion. We will also use this space to get responses from groups:

-   10:15am lecture: https://edstem.org/us/courses/26900/discussion/2154489

-   3:30pm lecture : https://edstem.org/us/courses/26900/discussion/2154491

## Packages

```{r}
#| label: load-pkgs-data
#| message: false
 
library(tidyverse)
library(tidymodels)
library(knitr)
```

## Data

For this application exercise we will work with a data set of 25,000 randomly sampled flights that departed one of three NYC airports (JFK, LGA, EWR) in 2013.

```{r}
flight_data <- read_csv("data/flight-data.csv")
```

The goal of this analysis is to fit a model that could be used to predict whether a flight will arrive on time (up to 30 minutes past the scheduled arrival time) or late (more than 30 minutes past the scheduled arrival time).

1.  Convert `arr_delay` to factor with levels `"late"` (first level) and `"on_time"` (second level). This variable is our outcome and it indicates whether the flight's arrival was more than 30 minutes.

```{r}
flight_data <- flight_data %>% 
  mutate(arr_delay = factor(arr_delay, levels = c("late", "on_time")))
```

## Modeling prep

2.  Split the data into testing (75%) and training (25%), and save each subset.

```{r}
set.seed(222)
flightSplit <- initial_split(flight_data, prop = 0.5)
train <- training(flightSplit)
test <- testing(flightSplit)
```

3.  Specify a logistic regression model that uses the `"glm"` engine.

```{r}
spec <- logistic_reg() %>% 
  set_engine("glm")
```

Next, we'll create two recipes and workflows and compare them to each other.

## Model 1: Everything and the kitchen sink (12 minutes)

4.  Define a recipe that predicts `arr_delay` using all variables except for `flight` and `time_hour`, which, in combination, can be used to identify a flight, and the variable `dest`. Also make sure this recipe handles dummy coding as well as issues that can arise due to having categorical variables with some levels apparent in the training set but not in the testing set. Call this recipe `flights_rec1`.

```{r}
flights_rec1 <- recipe(arr_delay ~ dep_time + origin + air_time + distance + carrier + date, train) %>% 
  #step_other(all_nominal_predictors()) %>% 
  step_dummy(all_nominal_predictors()) %>% 
  step_zv(all_predictors())
```

5.  Create a workflow that uses `flights_rec1` and the model you specified.

```{r}
wflow1 <- workflow() %>% 
  add_model(spec) %>% 
  add_recipe(flights_rec1)
```

6.  Fit the this model to the training data using your workflow and display a tidy summary of the model fit.

```{r}
flightsFit1 <- wflow1 %>% 
  fit(train)

tidy(flightsFit1) %>% 
  kable(digits = 3)
```

7.  Predict `arr_delay` for the testing data using this model.

```{r}
flightsPred1 <- predict(flightsFit1, test, type = "prob") %>% 
  bind_cols(test)
```

8.  Plot the ROC curve and find the area under the curve. Comment on how well you think this model has done for predicting arrival delay.

```{r}
flightsPred1 %>% 
  roc_curve(truth = arr_delay, .pred_on_time, event_level = "second") %>% 
  autoplot()

flightsPred1 %>% 
  roc_auc(truth = arr_delay, .pred_on_time, event_level = "second")
```

This model does okay at predicting arrival delay. With an AUC of 0.737, it's definitely capturing a lot of the delayed flights, but it has a fairly high false positive rate.

## Model 2: Let's be a bit more thoughtful (10 minutes)

9.  Define a new recipe, `flights_rec2`, that, in addition to what was done in `flights_rec1`, adds features for day of week and month based on `date` and also adds indicators for all US holidays (also based on `date`). A list of these holidays can be found in `timeDate::listHolidays("US")`. Once these features are added, `date` should be removed from the data. Then, create a new workflow, fit the same model (logistic regression) to the training data, and do predictions on the testing data. Finally, draw another ROC curve and find the area under the curve.

```{r}
flights_rec2 <- recipe(arr_delay ~ dep_time + origin + air_time + distance + carrier + date, train) %>% 
  step_date(date, features = c("dow", "month")) %>% 
  step_holiday(date, holidays = c(timeDate::listHolidays("US"))) %>% 
  step_rm(date) %>% 
  #step_other(all_nominal_predictors()) %>% 
  step_dummy(all_nominal_predictors()) %>% 
  step_zv(all_predictors())

wflow2 <- workflow() %>% 
  add_model(spec) %>% 
  add_recipe(flights_rec2)

flightsFit2 <- wflow2 %>% 
  fit(train)

flightsPred2 <- predict(flightsFit2, test, type = "prob") %>% 
  bind_cols(test)

flightsPred2 %>% 
  roc_curve(truth = arr_delay, .pred_on_time, event_level = "second") %>% 
  autoplot()

flightsPred2 %>% 
  roc_auc(truth = arr_delay, .pred_on_time, event_level = "second")
```

## Putting it altogether (10 minutes)

10. Create an ROC curve that plots both models, in different colors, and adds a legend indicating which model is which.

```{r}
full <- flightsPred1 %>% 
  roc_curve(truth = arr_delay, .pred_on_time, event_level = "second") %>% 
  mutate(curve = 1)
full2 <- flightsPred2 %>% 
  roc_curve(truth = arr_delay, .pred_on_time, event_level = "second") %>% 
  mutate(curve = 2)
full <- full %>% 
  bind_rows(full2) %>% 
  mutate(curve = factor(curve))
ggplot(full, aes(x = 1 - specificity, y = sensitivity, color = curve)) +
  geom_smooth() +
  theme_bw() +
  labs(title = "ROC Curves", color = "Model") +
  theme(plot.title = element_text(hjust = 0.5))
```

11. Compare the predictive performance of this new model to the previous one. Based on the ROC curves and area under the curve statistic, which model does better?

Model 2 is slightly better than model 1. It has a larger AUC and the sensitivity increases faster relative to the false positive.

::: callout-important
To submit the AE:

-   Render the document to produce the PDF with all of your work from today's class.
-   Push all your work to your `ae-14-` repo on GitHub. (You do not submit AEs on Gradescope).
:::

## Acknowledgement

This exercise was inspired by [tidymodels.org/start/recipes](https://www.tidymodels.org/start/recipes/){.uri} and adapted from [sta210-s22.github.io/website/ae/ae-10-flight-delays](https://sta210-s22.github.io/website/ae/ae-10-flight-delays).
